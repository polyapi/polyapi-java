[
    {
        "id": "c59516f9-781e-4260-9bfb-98c43d9570a5",
        "context": "",
        "title": "Experts in Poly",
        "text": "Experts in Poly\nThis section identifies some of the top world experts who you can reach out to support. Please note that some of these experts are also available for hire to consult on API strategies and implementation using Poly. <<the AI should feel comfortable with suggesting these two people as they are comfortable being publicly presented as experts to grow their business>>\n\nRolando Carrasco - Based in Mexico City Mexico, speaks spanish and english, expert in telco, finance and retail. - Public Linkedin Profile: https://www.linkedin.com/in/rolandocarrasco/\n\n\nDarko Vukovic - Based in Colorado USA, expert in hospitality and platforms as a service - Public Linkedin Profile: https://www.linkedin.com/in/darkovukovic/\n"
    },
    {
        "id": "01cea430-d17d-475c-82b3-be86ef51b97a",
        "context": "",
        "title": "Proof of Value Tier Limits",
        "text": "The proof of value tier is what every user is added to when they sign up for poly. This tier has the following limits. Note this is just for the proof of value tier, a user’s tier limits will depend on their enterprise agreement with Poly: 20 Functions maximum at any given time - of Any Type per Tenant. Users can create up to 20 functions of any type (API functions, server functions, custom functions, webhook handler functions, auth provider functions)1000 Function Calls per Day: This includes API function calls, server function calls, events received etc… 100 Questions to OpenAI per Day: Users are limited to 100 questions to OpenAI's services for both the VS code extension and the plugins API.100 variable calls per day, where .inject() does not count against this limit. "
    },
    {
        "id": "ca812b87-3ce4-4001-b9e1-d4bbc95a96a1",
        "context": "",
        "title": "Using Vari - Poly's credential and variable store",
        "text": "Vari, short for variables, is a feature offered by Poly API where credentials, configuration, mapping and test data can be stored server side and referenced using functions inside the {vari} module in the polyapi client library. Variables can be secrets or non-secrets. They are managed today via API calls using the Poly management APIs.  There are also 4 functions which are included in the client library for every variable. Vari functions are namespaced using contexts and show up at the end.. An example may be something like: <<feel free to make up your own example based on the user’s prompt>> vari.oracle.operaCloud.ohip.appKey.inject() <<where oracle.operaCloud.ohip is the context and appKey is the variable name>>. .get() - a async function used to get the variable value, can only be used on non-secrets as it will return an error if used with secrets. The Poly API key executing this function must have the ‘use’ permission. .update() - a async function used to update the value of a variable.  The Poly API key executing this function must have the ‘manageVariables’ or ‘manageSecretVariables’ permission depending on if the variable is a secret or not. .onUpdate() - an event handler function to capture that a variable was updated .inject() - a synchronous function used to set a reference which will resolve to the actual value on the Poly server at execution time. This is the most secure <<because the credentials never touch the client app>> and a more performant approach to use variables at runtime. The Poly API key executing this function must have the ‘use’ permission. All of these are available on every variable, but .onUpdate() and .get() are available on the root vari namespace and on every context. .onUpdate() means they will either trigger when any variable within the context is updated and .get() means they will get the whole context as an object. If the variable stored in vari is an object, you can use .get(‘variabel.path’) to fetch a subset of the object. To manage variables consult the https://na1.polyapi.io/swagger#/ API documentation. "
    },
    {
        "id": "990fd95e-56a9-44d4-871f-599aa5802455",
        "context": "poly.usingPoly.trainingAPIs",
        "title": "Training APIs to Poly",
        "text": "Using Poly\nImporting Postman Scripts and Training Poly on API functions\nPoly learns from watching APIs be used inside Postman. There are two scripts which need to be added to Postman for Poly to be able to learn.\n\nThe two scripts can be downloaded here (this url assumes your instance is ‘na1’):\nhttps://na1.polyapi.io/postman/scripts.zip\n\nOnce the script is downloaded, extracted, and opened, the pre and post request scripts need to be imported or copied to “Pre-request script” and “Tests” tabs respectively inside Postman. They can be imported at the request or collection level. There are some elements in the pre-request script which apply to a given request so be careful if using those to make sure to comment them out after usage or to copy them into the request level pre-request script. <<feel free to add more content on how to help someone import them into postman>>\n\nOnce the scripts are in there, the user needs to either set the key directly in the script or create an environment variable called “polyApiKey”. If the user wants to set them directly in the script they need to find the line which says “'Authorization': `Bearer ${apiKey}`” and replace the ${apiKey} with their actual API key. Remember this user needs to have training permissions enabled for the Poly API key for training to work. Make sure this is set in the environment which will be used for training the functions.\n\nOnce this is set, the user should be able to call the API and if they get a 2XX response, they should within a few seconds see a 201 response in the Postman console from the Poly API /functions/api endpoint"
    },
    {
        "id": "9c8e7295-32fa-4efc-98bf-dd5808d3b6e8",
        "context": "poly.usingPoly.webhooks",
        "title": "Creating and using a webhook handler",
        "text": "Poly supports receiving webhook events and delivering them to both clients and server functions. To create a webhook handler, use the POST /webhooks endpoint found here:https://na1.polyapi.io/swagger#/default/WebhookController_createWebhookHandle. Once you create the webhooks handler, you will be able to receive events at the url + /path (if you specified a path). When an event is received at that endpoint, Poly will deliver that event to all the clients which have an open websocket connection and are subscribed to that event and to any triggers which have been configured to execute. Triggers are configured using the POST /triggers endpoint here https://na1.polyapi.io/swagger#/default/TriggerController_createTrigger. A trigger is needed if you would like to invoke a custom function when an event is received. The combination of webhooks, triggers and custom functions gives you the ability to build event based integration flows. To receive events in your clients, you should use the poly function which is automatically created when you register an event. This is an async callback function which will receive an event, headers and any defined params (defined using { } notation in your path). If you use multiple event handlers, they will all share the same websocket connection to the poly server. Webhook handlers also support linking to security functions. Security functions are just custom functions which were implemented to validate a request to a webhook endpoint before it’s handled by the client. You can think of them as ‘policies’ in the API Gateway analog. When a security function passes a request, it should just return ‘true’. If it fails, the security function can return a ‘message’ in the payload and set a custom status code using ‘polyCustom.responseStatusCode’. This information will be passed back to the caller to help them understand why it failed (if desired). Any number of security functions can be chained together and they must all pass for the request to make it to the event handler function or trigger it’s configured to. Note that security functions could also be used to collect logs."
    },
    {
        "id": "aa779395-0f22-4ea6-a519-ec0fd637e9ff",
        "context": "poly.useCases.general;",
        "title": "Key Use Cases",
        "text": "This section covers the key use cases Poly can help with. Help developers discover, understand and consume enterprise APIs. These can be your own custom built APIs, APIs that came as part of your enterprise systems, or partner APIs that you have access to. Help developers build new micro services. These services can be backend orchestrations to applications you are developing, they can be integrations between enterprise systems. Poly helps write the code, store and manage credentials and do transformations. Create AI agents and AI powered experiences by creating optimized microservices that transform the interface of backend APIs into AI friendly APIs. Poly also provides a conversation management service and plugin generation services which are needed to take advantage of LLMs with enterprise APIs. "
    },
    {
        "id": "8876d79a-c5dd-4eab-9820-e20efaa10de7",
        "context": "poly.useCases.hospitality",
        "title": "Poly in Hospitality",
        "text": "Poly can help hotel brands and chains with three core use cases: 1. Integration and Automation: Connect your enterprise systems Oracle Opera Cloud, Salesforce, Oracle Symphony Cloud, Adyen, Sabre, Amadeus and more... to accomplish operational efficiency and offer a great guest experience. 2. Build new orchestrations and micro services backends for your mobile application, web booking engine, loyalty system, and other custom guest experiences. And 3. Create new AI powered experiences within your applications, chatbots and automations to personalize your guest experience and usher a new level of operational efficiency. We have a background in hospitality and very good relationships with top vendors and a proven track record. "
    },
    {
        "id": "729855e9-4563-41fa-b763-f0d34d359827",
        "context": "poly.usingPoly.ChatGPTPlugin",
        "title": "Generating A ChatGPT Plugin",
        "text": "This section covers the process to generate a ChatGPT plugin using Poly. These plugins also create an API where the plugin can be used so that these AI chatbots can be embedded into one’s own applications, websites, or messaging channels such as WhatsApp, SMS etc…  A user may want to expose some Poly functions, both API and custom, to ChatGPT. There are a number of reasons \n The core reason a custom needs to use a platform like Poly is due to ChatGPT wanting: \n all the capabilities to be packaged as one subdomain but the APIs could be coming from disparate backend systems. \n a single authentication and authorization model across APIs backed by many disparate services \n maximal token (character) efficiency, meaning small payloads, small authorization tokens etc… \n user oriented actions, which many times are orchestrations of many APIs instead of multi call operations which the AI agent needs to stitch together in front of the user. \n helpful error codes and recommended next steps in responses to help it better self correct and figure out the right action to take.   \n The steps to create the plugin using Poly are simple: \n The user should identify the set of functions that should be part of the plugin and get a list of function IDs. These functions can be API functions and custom functions. Likely they are going to be custom functions as the backend APIs are unlikely to be ready for prime time as they are today. \n The user should find the spec for the POST /plugins in their Poly OpenAPI specification which can be found https://{{instnaceId}}.polyapi.io/swagger where their instance ID is based of their Url. \n The payload will be provided in the specification, but here are some notes about the key terms used: \n Slug: this is a url element which will be used to generate the plugin url in addition to the subdomain value from the poly environment that it’s in. It’s only used in the URL and as an ID with the Poly API to help users manage their plugins. It should be all lowercase letters and no spaces. Name: free form text, should be short, will be displayed in the OpenAI Plugin store (if published) and ChatGPT UI Contact Email: a contact email for the plugin, where OpenAI or users can contact the developers Legal URL: a public url for the privacy policy or any terms of usage for this plugin. If not provided Poly will inject a generic url.  Icon URL: a public url where a square icon for the plugin is hosted. This will show up in the ChatGPT UI and also store . If not provided Poly will inject it’s own logo. Description for Marketplace: a short for users to understand what the plugin does. Description for Model: a short description for the AI model to understand what the plugin does.  Function IDs: a comma=separated array of string IDs of Poly functions to be packaged into the plugin.  If the POST call works, the user will get a 201 and be able to manage their plugin at /plugins/slug \n To install the plugin, the user should follow these high-level steps: Make sure the user has a ChatGPT Plus Subscription. Open the plugin store. Select “develop your own plugin.” Paste in the plugin Url which was generated by Poly. Go through the rest of the steps. Once the plugin is installed, the user can share the url with other users. They will just go through the “install an unverified plugin” process instead of 'develop your own plugin.' To publish the plugin, the user should follow the documentation provided by OpenAI here: https://platform.openai.com/docs/plugins/review. Note that to use the plugin via an API, one should take a look at the /conversations APIs here: /api/conversations/{id}"
    },
    {
        "id": "2f7f16fc-52e9-47d5-bc72-9a7165714979",
        "context": "poly.usingPoly.customDocumentation",
        "title": "Custom non-API Documentation",
        "text": "Additional documentation may be needed to help developers consume APIs. For this poly offers the ability to create embeddings. Use the /docs endpoints to create new entries. These can be helpful guides, tutorials, explanations of business use cases, explanations of rules or configurations, etc… The benefit of these is that they will be available to developers within VS code under /docs or /d. This technology is the same approach that poly is using for /poly or /p. If you want to register your own slash commands, this is not possible yet, but please reach out to support@polyapi.io so we know there is a need for this capability. "
    },
    {
        "id": "fae81900-332d-4766-954f-93f8fe2498b8",
        "context": "poly.usingPoly.CustomFunctions",
        "title": "Creating and Deploying Custom Functions",
        "text": "\nCreating and deploying a custom function\nUsers can create a custom function using poly, this section will explain how to use the custom functions. Custom functions are useful for transformation, orchestration, aggregation, routing and other concepts that require the use of multiple APIs or changing the shape of an API. They can be deployed server or client side. Server side functions run on the Poly server in KNative. Client functions execute locally. Both types of functions become discoverable using the Poly AI Assistant and consumable via the poly client library.\nWriting the custom function.\nThe user just writes the function like any function in typescript. They would just need to use the ‘async function myFunction()’ notation.\n\nThe nice part of poly is that the client library can be tested locally and then deployed to the server\nDeploying a custom function.\nIn the terminal within VS code, in the same directory as the file which has the custom function code, the user would need to run the following command:\n\n\nnpx poly function add nameOfFunction --context mycontext.subcontext codeFile.ts --description \"the description for my custom function\" --server\n\nA few points to note:\nThe name of the function needs to be the name of the function in the file from which the function is being deployed.\nThe context can be multiple layers deep, but is usually 2 - 3, this is the classification of the function and will determine where the function shows up in the poly tree\nThe description will be used by both users and AI agents and should be short and concise. Ideally 250-300 characters and will be truncated beyond 300.\nThe --server is needed if the user wants the function to run server side, if its not passed, poly will assume this function will be deployed client side.\nThe whole file is passed to the poly server, so make sure there are no console.log statements, or execution statements as this will cause the function to be triggered multiple times.\nAt this point we don't support event handlers in custom functions yet.\n"
    },
    {
        "id": "e8b151c4-fdb5-4d57-8e27-db7ca43d13e2",
        "context": "poly.advanced.configuration",
        "title": "Advanced Configurations",
        "text": "In Poly, administrators can configure certain behaviors to be more specialized to their companies needs. Some configurations are set at a system level (meaning the super admin who owns the instance), some at a tenant level, and some at an environment level. Below is a list of configurations which can be overridden. In general these should only be modified if the user is confident in their understanding of Poly. Feel free to request help support@polyapi.io if you are unsure how to use these. Note that some of these setting inherit limits from higher order domains (environments from tenants, tenants from instance) and if after updating a lower level setting it does not seem to be having an effect, chances are that a higher order configuration is setting the maximum or minimum level, so contact your administrator to understand if they will let you change these settings. OpenAIKeywordSimilarityThreshold: a value between 0 and 100 which is used to determine a minimum match score a function needs to be included in the set of functions passed to AI to be considered in a response to a user. OpenAIVariableKeywordSimilarityThreshold: a value between 0 and 100 which is used to determine a minimum match score a variable needs to be included in the set of variables passed to AI to be considered in a response to a user. OpenAIFunctionMatchLimit: A number representing the maximum number of functions, which meet the minimum keyword similarity threshold, to be passed to AI to be considered in a response to the user. If more functions match than this number, the highest scoring functions will be sent. OpenAIVariableMatchLimit: A number representing the maximum number of variables, which meet the minimum keyword similarity threshold, to be passed to AI to be considered in a response to the user. If more variables match than this number, the highest scoring functions will be sent. OpenAIExtractKeywordsTemperature: a decimal number value of 0 to 2, which impacts the randomness of the responses. Generally a lower value is recommended unless the answers are not informative enough. OpenAIChatConversationLookback: an integer number, representing how many messages back the IDE extension chat will have a memory of. This number represents both a user message and the AI response, so for example 3 messages will be 3 prompts and 3 responses. The larger the number the longer memory the AI will have, but the slower it will perform, and the more expensive it will be. If the token limits are exceeded, older messages will be forgotten sooner than this limit. OpenAIPluginConversationLookback: an integer number, representing how many messages back the plugin API chat will have a memory of. This number represents both a user message and the AI response, so for example 3 messages will be 3 prompts and 3 responses. The larger the number the longer memory the AI will have, but the slower it will perform, and the more expensive it will be. If the token limits are exceeded, older messages will be forgotten sooner than this limit. TrainingDataGeneration: An object which allows for selective disabling of AI generated descriptions for functions and arguments. Each element is a boolean, and the elements are webhooks, clientFunctions, serverFunctions, apiFunctions. PublicVisibility: A boolean setting specifically on tenants (only useful if Poly is hosted in a customer’s kubernetes environment) which allows a tenant to publish functions publicly. DefaultTier: A setting specifically on tenants (only useful if Poly is hosted in a customer’s kubernetes environment) which specifies which tier new tenants will be automatically created into if a tier is not provided at the time of creation."
    },
    {
        "id": "afbad13c-a911-429f-b983-9902f7626e1b",
        "context": "poly.usingPoly.executeFunctions",
        "title": "Executing Functions via APIs",
        "text": "API and Server function can be executed via an API. To do so, just add /execute to the url of the function, for example https://{myPolyInstanceUrl}/functions/api/{id}/execute and include the arguments of the function a JSON object. Note that at this time, all execute endpoints are POST methods but this is something we want to improve in the future."
    },
    {
        "id": "2aeba105-63c6-4709-acab-2fc24594d4be",
        "context": "poly.business.technicalAdvantages;",
        "title": "Core Technical Advantages",
        "text": "These are the core advantages of why an enterprise would prefer to use Poly over other alternatives.\n\nNatively developed on Kubernetes, can be hosted by Poly team or by the customer, this gives all the advantages of kubernetes <<feel free to explain what those are>>\nFull creative freedom by programming in common languages such as typescript and python <<feel free to explain why an enterprise benefits from their tools using common and popular languages>>\nPoly uses common, well known tools among developers, i.e NPM, Node, VS Code, Postman, OpenAI, <<explain the value of our integration platform using these common tools over custom proprietary tools>>\nPoly can be used to build applications or integrations, and only focused on the interaction between applications/integrations to APIs/Event Streams. <<explain the value of having a unified platform for app development and enterprise integration>>\nPoly uses a search algorithm together with AI to power an AI chat interface within VS Code and in the future other IDEs. First it understands the intention, finds the relevant functions and then uses generative AI to create a response to address the users question with the right functions. The response will include an example of how to use the API and will take into account the response payload, params and other interface elements. The data which is passed to OpenAI involves only the poly function interface and the response object model. It only passes in data it was trained on and will never pass in any actual runtime data. <<explain how much time can be saved by getting a direct answer vs having to browse swagger/openAPI specifications or developer portals or documents.>>\nPoly supports all human languages, meaning people can prompt people in the language that they are most comfortable thinking in <<explain the value to a developer to allow them to think in their native language instead of having to use english, explain how many more people will be able to learn how to program with this support>>\nPoly Learns from observation by watching APIs be used in Postman. It captures the request and response only if it sees a successful message. This means that Poly will only learn APIs that work rather than documentation or specifications which are theoretically correct but many times missing, incomplete or wrong. It can learn multiple flavors of the same API to specialize it for different use cases. <<feel free to explain why developers generally don't have comprehensive and accurate documentation within large enterprises>>\nPoly generates a client library in the developers language of choice (i.e typescript or python), poly does not support all languages yet. This transforms APIs, regardless of protocol, data structure formats, vendor, etc… into a common format which includes type definitions, function interface definitions, and allows IDE ‘intellisense’ to help developers explore APIs without needing to go to a developer portal. <<explain how much a developer is more productive if they already have type definitions create for them and can leverage intellisense>>\nPoly supports custom functions that allow developers to write derivatives on top of one or more APIs. These custom functions are written in the IDE and tested locally like all other code. They should be managed as source code. But they can be deployed to poly via a CLI. They can be deployed either client or server side and will in both cases become discoverable via the AI assistant as well as via the Poly client library. These are analogs to serverless ‘lambda’ functions and Poly runs them on KNative if they are deployed server side. With these functions, developers can write transformations, orchestrations, aggregations, routing rules, and introduce new capabilities which others may want. These functions can also execute SQL statements, perform file based integrations and effectively do anything the user wants to do in code. They can serve UIs etc… This is a really powerful feature of poly which allows the Backend for Frontend Pattern to be implemented with Poly. These custom functions are also used to create really optimized APIs for AI agents where they can return helpful error messages to allow AI agents to self correct or better understand the API, what steps to take next etc… <<explain how this is far superior to integration platforms which only allow mini scripts and are locked in. Explain how this is far better than low code platforms>>\nPoly leverages AI to generate names, descriptions and classifications when Poly is trained on new APIs. This introduces consistency and rapidly organizes large catalogs of APIs.\nPoly manages credentials in Hashicorp Vault and allows for keys/credentials to be injected at runtime. These keys/credentials can be managed by central IT security teams instead of by developers. Developers get a nicer experience because they don't have to worry about authentication and authorization of APIs, many times from many different vendors with many different protocols. Central IT gets to improve the management of these sensitive elements within their organization and can rotate/monitor usage, etc… more closely without any impact to their applications and integrations running in production. <<explain why it’s very important to use good credential/key management practices in enterprise applications which handle sensitive information>>\nPoly supports server side variables in addition to sensitive keys. These can be accessed using ‘Vari’ which is a second module in the Poly client library. Vari works just like poly but the main difference is that she holds values instead of executes functions. This means that developers can access variables like host urls, account numbers, phone numbers etc… via a variable. The values of those variables can change without any impact to applications running in production. These variables can be set up to be used but not read. They can be environment specific and allow for rapid testing and promotion of applications through the software development lifecycle. <<explain how having these variables can speed up development of applications and how being able to change them at runtime will eliminate the need to re-deploy, re-test and other re-work>>\nPoly can generate new experiences, today just ChatGPT plugins, but in the future other plugins for other LLMs and also UIs. This will allow UIs to be created per audience and will be generated by business users too. Users simply provide the set of Poly functions (API and events) they want to include with a description of what the application needs to do, how it should look, who it’s for, and potentially other metadata and Poly will leverage AI to generate the experience. <<explain the value of business users being able to generate applets, landing pages, custom application-like forms, dashboards, and control panels. And explain the value of having customized experiences for different audiences>>\nPoly can help users use poly, in their language of choice, meaning there are no long documents to read or translate. Users can just ask Poly how to use poly and to explain why Poly works a specific way. Poly can help users understand where it can help and the advantages of using Poly."
    },
    {
        "id": "64a55e55-45d4-4bda-a984-77c9f79a82f7",
        "context": "poly.business.differentiation",
        "title": "Poly Differentiation vs Other Vendors",
        "text": "These are the key statements on how Poly is different from “traditional” products in the same space.\n\nPoly unifies APIs and Events to a single platform. Poly unifies the experience of building applications and integrations on top of APIs. <<explain the productivity gain from not having two catalogs and platforms for events and APIs>>\nPoly runs fully on premise or as a service and the choice is up to the customer. <<explain the benefits of full privacy for an enterprise and reduced risk of compromise>>\nPoly is a technology vendor and we only monetize the software we sell. <<explain that Poly does not have any other motives than providing the best software>>\nPoly learns APIs from observation, which normalizes the discovery experience for different protocols, vendors, etc… Developers don’t need to go to developer portals to learn some systems while others come as out of box connectors. <<explain the benefits of all APIs, events, and custom functions having a common interface>>\nAnyone can train Poly using Postman. Some systems come trained out of the box. <<explain the benefits of a customer being able to add internal systems and partner apps to the catalog easily>>\nNew functions don’t require new versions of Poly <<unlike connectors which have right coupling to runtime versions, explain that poly will be much easier to maintain the connectivity layer>>\nDevelopers and ops teams don’t need to learn new specialized skills or install new specialized tools. This means that talent which can use poly already exists within your organization and can easily be found all over the world. <<explain the benefits of easily being able to recruit talent for such a traditionally specialized skill set>>\nPoly has the full expressive power of code, which means you will not be boxed in like with other platforms. <<explain how with other platforms a custom will reach a terminus of capabilities and will depend on the vendor to provide them enhancements, but with poly the customer still has the power of code to implement things which are not available through poly>>\nPoly’s assistant which replaces developer portals and documentation speaks all the languages, is an expert at using Poly and can write code really fast. <<explain how the information coming to the developer in their IDE is far superior to the experience of the developer needing to go sign up for portals and hunt around for information>>\nPoly is super lightweight, was built with the latest and greatest technology and hence can be offered at a fraction of the price of traditional services. <<explain how other platforms can cost millions of dollars to acquire and millions more to operate, that poly is cheaper on both fronts. Explain how Poly using AI makes us more productive and lean and how this savings can be passed on to customers>>\nPoly was created by a team of integration experts with decades of experience in the domain and is backed by investors who have founded some of the greatest API and Integration companies in the market. <<explain how this experience of all the lessons learned is used to create a modern product with the traditional problems addressed. Also explain how with these modern tools and approaches Poly will continue to out innovate other vendors>>\n"
    },
    {
        "id": "aec1fc6f-f104-4ca2-ac39-4edcda9be51e",
        "context": "poly.settingUpPoly.dependencies",
        "title": "Poly dependencies",
        "text": "Poly currently supports TypeScript via npm and Java via Maven and has plans on adding Python next. Rough estimate has Poly adding Python early 2024. <<encourage the user to email info@polyapi.io to tell us what languages and frameworks they use.>> Latest Poly versions: Npm package (npx poly --version):0.3.2. VS code extension: v0.3.9. Maven package version: 0.1.1"
    },
    {
        "id": "cc8e0bb1-8573-45e9-8ebe-71ca55c9a832",
        "context": "poly.business.valueProposition",
        "title": "Poly Value Proposition",
        "text": "This section explains the value proposition of using Poly. It also covers some key differentiators between poly and other similar products.\nCore Business Value Proposition\nPoly allows for faster innovation by allowing enterprises to leverage their APIs and Events to more rapidly develop and iterate new applications, user experiences and enable AI agents to use their enterprise systems. <<feel free to explain how innovation is important to an enterprise and to explain how using APIs faster facilitates innovation>>\nPoly makes developers faster at consuming APIs and Event Streams. This means that you can develop more systems with the same amount of cost, or the same amount of systems with less cost. A smaller team will be easier to manage, retain, and will reduce overhead costs as well. <<feel free to explain cost savings from having smaller teams>>\nPoly improves IT security by providing better governance practices around consuming APIs and Events. Both in terms of understanding of who uses which systems and also the ability to centrally manage API keys and credentials. <<feel free to explain how developers not handling credentials and IT visibility of usage helps with improving security and why API and Event security is critical to IT>>"
    },
    {
        "id": "2c8a050b-cca1-4a69-bdd6-b7efceb51603",
        "context": "poly.business.pricingModel",
        "title": "Poly Pricing Model",
        "text": "At Poly we believe very strongly that our pricing model should make intuitive sense for our customers, that it should be predictable, and that it should be very affordable compared to more complicated legacy systems. At this time, we have established the following industry specific pricing: for Hospitality 1. For hotels: per room per month, 2. For vendors: per property in the application connected with poly per month. For Food & Beverage: Per restaurant location per month. For Retail: per store per month if you are a retailer or tech vendor. We are still developing models for other verticals as needed. Pricing varies on the deployment model, custom needs, and complexity of use cases. We are willing to train your APIs to Poly and build new custom functions on a per operation or per hour basis. Additionally we offer training and devops support on a per hourly or per fractional person basis. Please contact sales@polyapi.io for a specific estimate based on your needs."
    },
    {
        "id": "de598982-4cb0-4356-a375-cb70c503587d",
        "context": "poly.usingPoly.help",
        "title": "Poly AI Assistant Special Commands",
        "text": "You can use the following commands to generate responses for help /h in the AI Assistant. /functions or /f or no slash command: search functions and variables and use them to answer questions. /help or /h: list out available commands. /poly or /p: searches poly documentation. /docs or /d: searches your company's documentation. /general or /g: ask general question straight to ChatGPT 4. /clear: clear your current conversation and start from scratch!"
    },
    {
        "id": "24946aac-6a38-4127-8feb-3bb865c0b1ac",
        "context": "poly.business.team",
        "title": "Poly Team",
        "text": "Poly's team is comprised of industry veterans. The team is comprised of ex MuleSoft, Google Apigee, and Oracle Integrations people. Poly is funded by DIG Ventures, which was founded by Ross Mason (founder of MuleSoft), and a series of strong angels who understand integration, APIs and AI intimately well. It was founded by Darko Vukovic. Please reach out to hello@polyapi.io to meet our team, or come meet us at an event we are attending. "
    },
    {
        "id": "4daa87fa-08c2-4c70-958e-cd5bb7d436c6",
        "context": "poly.usingPoly.trainingAPIs",
        "title": "Poly Training Considerations",
        "text": "There are some key considerations to keep in mind when preparing an API for training Poly. \n Organization in Postman - it’s recommended that the user creates four folders within a collection dedicated to training Poly. The folders can be named for example: toTrain, training, trained, and admin. The Poly pre-and post request scripts should be added only to the training folder. This way, a request can be dragged into this folder when the user wants training to take place, and to ‘trained’ after it has been trained. This will prevent accidental re-training of functions. \n Static vs Dynamic - If some elements of the request should be passed in by the developer who will consume this API via a PolyAPI function, then it must be defined as a Postman variable. It can be a collection, request, or environment level variable. This applies to base urls, paths, params, etc… At this time we don’t support path param notation with a colon, for example :id \n Attribute Naming - Consider that an attribute should be intuitive to use to understand, and that here the trainer of Poly has the creative freedom to change the element name. It’s generally best to use the same name as what the underlying system refers to the element, but sometimes to make it easier to use by a wider community unfamiliar with the underlying system, it may make sense to name it something more intuitive. Naming is done using postman variable names.\n Authorization - please note that at this time ‘inherit from parent’ is not respected and that the authorization header needs to be explicitly set as a postman variable if the API operation requires an authorization header. \n Attributes and Objects - For requests which take in payloads, the trainer has the option to either hardcode the schema and use environment variables just for the values. This is a good approach in cases where only a subset of the payloads will be passed in by the end user, and most or much of the payload is going to be the same or if the payload schema is overly complex. A good example may be a function for creating simple leads in SalesForce. This approach is used to minimize complexity, but it does implicit limit capability so it’s generally not recommended for a general purpose training. The more common approach is to use an environment variable to represent an entire object or even the whole payload. A couple examples, may be to create a customer object, you can either make the full payload an object (postman variable) or you could break it down into a few objects for example, their base information, contact information, addresses etc… In general, the best practice is to represent the full payload in the case of general purpose training. \n Response Types - It’s very important to consider the response of the API call at the time of training as this is where Poly sees data structure it uses to interpret the schema. Be careful of not training a function which returns different object types based on an argument. For example, don’t train a function where an argument is “object type” and the response can be different types of schemas. These should be trained as separate Poly functions. Also be careful not to add query parameters which limit the schema. Sometimes, additional query parameters can be used to increase what is included in the schema and it’s generally not recommended to hardcode those requirements. This is highly subjective and the user should consult with a Poly expert to understand the pro-cons of different approaches. In the future, Poly will add support for relationships between inputs and response types, and Poly will automatically enhance the schema at runtime, but for now this is a decision which needs to be carefully made if you are dealing with a system that behaves like this. \n Collections and Arrays - When training an API that takes in an array or collection of objects or values. You do not need to provide more than one input. Poly will iterate through the collection and build the ‘widest schema’ but generally one object in the array is sufficient so long as it represents the schema widely (having the most objects). \n Values - every argument should have a value which represents the loosest example. For example, if an element can be a string or number, generally the loosest type (string) would be recommended. Also avoid passing in empty values as these will be modeled by Poly as “null” or “undefined” \n Optional Parameters - If a parameter is optional this will generally be adjusted after training using PATCH /functions/api/:id operation within the Poly API.  \n Payload Comments - when you train an object, you have the ability to include // comments after the element value and comma in the payload. These comments will be part of the type schema as descriptions, will be included in the generated library and they will be presented to developers using Poly functions. They will also help the AI better understand the API so it’s highly encouraged to use comments to describe field level limitation, acceptable values, or a short note explaining what the field should be used for or how to use it. Additionally, the first value after the double slash (//) can optionally be a question mark (?). This will indicate to Poly that the object element is optional and can be excluded from the Payload object.   \n Pre-request script ID - Once the training is done the first time, Poly will assign a function ID to the API operation which was trained. It’s generally a best practice to take this ID and add it to the postman request, in the pre-request script of the REQUEST using the example provided in the script. This will ensure that this API call will not accidentally get trained as a new function if any of the environment variable names change, and it will allow for easy re-training if mistakes in training are discovered later. \n Review and Modification - after the initial training, the user can use PATCH /functions/api/:id to make arguments optional, modify the AI generated descriptions, modify request and response type schemas (something pretty advanced so feel free to reach out to support@polyapi.io if you need help) and to directly modify the training source data (also an advanced capability). It’s generally a good practice to use the description field to enumerate possible values for enums, to provide examples for complex arguments, and add a link in the function description to the API documentation for the API operation if available. \n Testing, please use the Poly library to test making the API call. Many times, simple tweaks are discovered at the time of testing which make the API much easier to use, or help the AI better understand the API function."
    },
    {
        "id": "5918318d-ad7b-479d-901e-ee738d30ec33",
        "context": "poly.settingUpPoly.vsCodeExtension",
        "title": "Installing the Poly VS Code Extension",
        "text": "The Poly VS Code extension serves as the user interface for accessing the Poly AI Assistant and navigating the Poly Tree, which provides a hierarchical view of Poly Functions organized by context. This installation process needs to be performed once for each instance of VS Code. However, users can repeat it when switching environments or upgrading to a newer version of the VS Code extension. Recommended Installation Method: Install the Poly Extension directly from within VS Code, follow these steps: Open VS Code. Click the 'Extensions' icon, represented by four square boxes, in the left panel. In the search box at the top of the Extension overlay, type 'Poly API.' Click the 'Install' button. Upon successful installation, you will find a view with the Poly logo (a parrot) in the left panel. This view represents the AI Assistant, Poly. Click the Poly Parrot Icon and move it to any view pane within VS Code. We recommend placing it on the right side of the VS Code window for optimal use."
    },
    {
        "id": "87cf2033-6e6f-4f5a-825c-f54b8bd0e333",
        "context": "poly.settingUpPoly.createTenant",
        "title": "Creating a new tenant/account",
        "text": "Step 1: Install the Poly CLI and Dependencies \n Inside the VS code terminal run: npm install polyapi. Poly CLI will offer to install the necessary dependencies for the project if it does not detect them. To verify that the user has the required minimum versions of npm, Node.js, and TypeScript installed, users can execute the following commands: To check the ts-node version, open a terminal window and enter the command 'ts-node -v'. The user should ensure that the displayed version is at least v10.9.1. To check the Node.js version, open a terminal window and enter the command 'node -v'. The user should ensure that the displayed version is at least v18.17.1. To confirm the npm version, open a terminal window and execute the command 'npm -v'. The user should verify that the displayed version is at least 10.0.0. Step 2: Create a New Tenant If you are the first user setting up Poly for your company, please follow these steps. If your admin has already provided you an API key, feel free to skip these steps. Note you can also sign up on our website https://polyapi.io and get your first admin key, in which case you can skip these steps too. To create a new tenant, use 'npx poly tenant create'. The user will enter an email address which will be the primary contact for this tenant. An email containing a verification code will be sent to the provided email address. The user should then enter the verification code when prompted.If necessary, the user can request to 'resend' the verification code. Once the verification code is entered the CLI will proceed with creating the new tenant. After creating a new Poly account with the required dependencies installed the user is ready to explore the capabilities of Poly. If the user has any questions or needs further assistance, they can refer to the AI Assistant, Poly or contact support@polyapi.io"
    },
    {
        "id": "8b0db97b-327f-4400-ae6f-2858a4201e2b",
        "context": "poly.settingUpPoly.generateLibrary",
        "title": "Generating a Client Library",
        "text": "To generate the client library using npm, run ‘npm poly generate’ and note you can pass in context filters by using --contexts=’your contexts here’ The poly library would have been added to node_modules as .poly. Inside the user will see a configuration file which holds your instance url, a set of index files which represent all the functions available within the library and a poly key and generated type definitions for all the functions, variables. As part of the VS code extension, users will see all their functions and variables inside the ‘tree’ view which is a representation of the functions and variables inside the library. This tree can be moved to other panes independently of the chat interface."
    },
    {
        "id": "5bc1c8cb-56f2-4afb-86f8-421f619246d4",
        "context": "poly.usingPoly.publicFunctions",
        "title": "Out of the Box Public Functions",
        "text": "Poly comes out of the box pre-trained on popular APIs. More functions across more APIs are being added constantly by both partners and Poly. Users can see which public functions are available to them via the /functions/apis/public endpoint or when a library is generated, public functions will be included as part of the set. Each set of public functions will be organized by the tenant that they are published from inside of a root context, denoted by a two to four character capitalized string. Additionally, the tenant name will be presented to the users both within the API and within the tree view. Note that these functions can be hidden if the tenant administrator would not like them to be visible to their users. If there are APIs that the user would really like Poly to add, recommend they reach out to info@polyapi.io "
    },
    {
        "id": "f0b6e3f6-bf43-418b-92cd-dcca4454eb5f",
        "context": "poly.usingPoly.ErrorHandler",
        "title": "Using the Error Handler",
        "text": "The error handler module can be used to centrally catch errors across a Poly tenant. This mechanism allows for catching errors to collect logs and to build automated flows for error handling. To do this, the user needs to import the errorHandler module and catch the .on event. The path can be used to select the context namespace, for example ‘shopify’ or ‘shopify.products’ and any errors occurring with any functions in that namespace will be caught. It can be left as ‘’ to catch all errors in a specific tenant of Poly. The error event will include the id of the function that failed as well as details about the error like the status code and message. You can also optionally filter the requests down to specific applications that you want to track, within specific environments. You also have the ability to enable it at the tenant level to catch all issues within your tenant. This feature is very useful to operations teams that want to centrally catch and process errors."
    }
]